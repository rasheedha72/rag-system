# RAG Chatbot System

A production-ready Retrieval Augmented Generation (RAG) chatbot built with FastAPI, Streamlit, and LangChain.

## ğŸ¯ Features

- **Vector Search:** FAISS-powered semantic document retrieval
- **LLM Integration:** Groq API for fast inference
- **REST API:** FastAPI backend with CORS support
- **Interactive UI:** Streamlit frontend for easy testing
- **Source Citations:** Automatic document attribution

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Groq API key: https://console.groq.com

### Installation

Clone repo
git clone https://github.com/rasheedha72/rag-system.git
cd rag-system

Create virtual environment
python -m venv .venv
.venv\Scripts\activate

Install dependencies
pip install -r requirements.txt

Add API key
echo "GROQ_API_KEY=your_key_here" > .env

text

### Run Locally

**Terminal 1 - FastAPI:**
uvicorn app:app --reload --port 8000

text

**Terminal 2 - Streamlit:**
streamlit run streamlit_app.py

text

Access at: `http://localhost:8501`

## ğŸ“ Project Structure

rag-system/
â”œâ”€â”€ app.py # FastAPI backend
â”œâ”€â”€ streamlit_app.py # Streamlit frontend
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ faiss_db/ # Vector database
â””â”€â”€ documents/ # Source documents

text

## ğŸ—ï¸ Architecture

User Query â†’ Streamlit UI
â†“
FastAPI Server
â†“
Vector Retrieval (FAISS)
â†“
LLM Generation (Groq)
â†“
Answer + Sources

text

## ğŸ“Š Performance

- Retrieval: <100ms
- LLM Response: 1-2 seconds
- Total: <3 seconds per query

## ğŸ¤ Contributing

Feel free to fork, modify, and improve!

## ğŸ“ License

MIT

---

**Status:** Day 2 Complete âœ…
**Next:** Optimize & Deploy to Hugging Face
Then commit and push:

bash
git add README.md
git commit -m "Add comprehensive README documentation"
git push origin main